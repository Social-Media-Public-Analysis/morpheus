{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "average-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "from murphy.nlp_tools import NLPTools\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from emoji import UNICODE_EMOJI\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from tpot import TPOTClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process daily data to \n",
    "# checking to see if there's an emoji in the text\n",
    "def is_emoji(s):\n",
    "    count = 0\n",
    "    for emoji in UNICODE_EMOJI:\n",
    "        count += s.count(emoji)\n",
    "        if count > 1:\n",
    "            return False\n",
    "    return bool(count)\n",
    "\n",
    "def extract_emojis(s):\n",
    "    return ''.join(c for c in s if c in UNICODE_EMOJI)\n",
    "\n",
    "for day in tqdm([1,2,4, 5, 6, 7, 8, 9, 10]):\n",
    "    day = f'0{day}' if len(str(day)) == 1 else str(day)\n",
    "    tweet_df = DataLoading().get_twitter_data_as_bags(f'../../data/06/{day}/**/*').to_dataframe()\n",
    "    # selecting only the english language\n",
    "    tweet_df = tweet_df[tweet_df['lang'] == 'en']\n",
    "    # removing all of the tweets that are truncated\n",
    "    tweet_df['is_full_tweet'] = tweet_df.apply(lambda x: x['text'][-1] != '‚Ä¶', axis=1, meta=bool)\n",
    "    tweet_df = tweet_df[tweet_df['is_full_tweet']]\n",
    "    tweet_df = tweet_df[tweet_df['text'].apply(is_emoji, meta=bool)]\n",
    "    tweet_df['emojis'] = tweet_df.apply(lambda x: extract_emojis(x['text']), axis=1, meta=str)\n",
    "    tweet_df['emojis_count'] = tweet_df.apply(lambda x: len(x['emojis']), meta=int, axis=1)\n",
    "    tweet_df['text_without_retweets'] = tweet_df['text'].apply(lambda x: re.sub(r'RT @(.+?):', '', x), meta=str)\n",
    "    tweet_df = tweet_df[tweet_df['emojis_count'] == 1]\n",
    "    tweet_df[['text_without_retweets', 'emojis']].to_csv(f'text_emoji_data/text_emoji_data-{day}-*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dd.read_csv('../../text_emoji_data/text_emoji_data-*.csv')\n",
    "del tweet_df['Unnamed: 0']\n",
    "tweet_df = tweet_df.rename(columns={\"text_without_retweets\": \"text\"})\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_df = tweet_df.persist()\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_counts = tweet_df.groupby('emojis').count().compute()\n",
    "emoji_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_counts = emoji_counts.sort_values('text', ascending=False).head(10)\n",
    "emoji_counts = emoji_counts.reset_index()\n",
    "emoji_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = tweet_df.loc[tweet_df.emojis.isin(emoji_counts.emojis)]\n",
    "tweet_df_training_data.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "_demojifier_regex = r':.+?:'\n",
    "_username_regex = r'@.+? '\n",
    "\n",
    "def _remove_emojis(string: str):\n",
    "    string = emoji.demojize(string)\n",
    "    return re.sub(_demojifier_regex, '', string)\n",
    "\n",
    "def filter_emoji(twitter_dataframe):\n",
    "    twitter_dataframe['text'] = twitter_dataframe['text'].apply(_remove_emojis, meta=str)\n",
    "    return twitter_dataframe\n",
    "\n",
    "def _remove_username(string: str):\n",
    "    return re.sub(_username_regex, '', string)\n",
    "\n",
    "def filter_username(twitter_dataframe):\n",
    "    twitter_dataframe['text'] = twitter_dataframe['text'].apply(_remove_username, meta=str)\n",
    "    return twitter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = filter_emoji(tweet_df_training_data)\n",
    "tweet_df_training_data = filter_username(tweet_df_training_data)\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = tweet_df_training_data.persist()\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_obj = NLPTools()\n",
    "tweet_df = nlp_obj.run_tools(tweet_df_training_data)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = tweet_df_training_data.compute()\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data.to_csv('cleaned_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-military",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why like good series prime rather end watch mo...</td>\n",
       "      <td>ü§î</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u lie fyi bleach mha op one good</td>\n",
       "      <td>üëÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anonymous pull support politic brutality prote...</td>\n",
       "      <td>üëÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chicken skin https</td>\n",
       "      <td>üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yes pls</td>\n",
       "      <td>üò≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>I feel justice serve</td>\n",
       "      <td>üòÇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ugh choice stan https</td>\n",
       "      <td>ü•∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>damn miss highschool</td>\n",
       "      <td>ü•∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>look like get pair wood pigeon join flock https</td>\n",
       "      <td>ü•∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>its many fine people world wow I wan na travel...</td>\n",
       "      <td>ü•∫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201401 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text emojis\n",
       "2   why like good series prime rather end watch mo...      ü§î\n",
       "3                    u lie fyi bleach mha op one good      üëÄ\n",
       "9   Anonymous pull support politic brutality prote...      üëÄ\n",
       "13                                 chicken skin https      üòç\n",
       "15                                            yes pls      üò≠\n",
       "..                                                ...    ...\n",
       "57                               I feel justice serve      üòÇ\n",
       "58                              ugh choice stan https      ü•∞\n",
       "60                               damn miss highschool      ü•∫\n",
       "61    look like get pair wood pigeon join flock https      ü•∞\n",
       "62  its many fine people world wow I wan na travel...      ü•∫\n",
       "\n",
       "[201401 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_training_data = pd.read_csv('cleaned_training_data.csv', index_col=0)\n",
    "tweet_df_training_data = tweet_df_training_data.dropna(how='any')\n",
    "tweet_df_training_data = tweet_df_training_data.drop_duplicates()\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.unique(tweet_df_training_data['emojis'])\n",
    "encoder = {lst[i]:i for i in range(len(lst))}\n",
    "tweet_df_training_data['keys'] = tweet_df_training_data['emojis'].map(lambda x: encoder[x])\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peaceful-rainbow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<201401x66464 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1071151 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts = CountVectorizer().fit_transform(tweet_df_training_data['text'].to_numpy())\n",
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pacific-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TfidfTransformer(use_idf=True).fit_transform(X_counts)\n",
    "y = tweet_df_training_data['emojis'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "covered-supplier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<151050x66464 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 803560 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "happy-machine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2567575619153542\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vertical-transmission",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v2thegreat/miniconda3/envs/murphy/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:05:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3410061369188298"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train, verbose=1)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "traditional-american",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT sparse', n_jobs=-1, random_state=42,\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tpot = TPOTClassifier(\n",
    "    verbosity=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    config_dict = 'TPOT sparse'\n",
    ")\n",
    "\n",
    "model_tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0aab1204d444174b9bffd50f4b5ee6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/10100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.3612578616352201\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.3612578616352201\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.3612578616352201\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.3612578616352201\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.36233035418735515\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.36233035418735515\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.36233035418735515\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.36246938099966897\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.3624826216484608\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.3624826216484608\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.36396557431314136\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.36396557431314136\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.36396557431314136\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.36396557431314136\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.36396557431314136\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.36398543528632904\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.36398543528632904\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.36398543528632904\n"
     ]
    }
   ],
   "source": [
    "model_tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tpot.export('test_model_3.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
