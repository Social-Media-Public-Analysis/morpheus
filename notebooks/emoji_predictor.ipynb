{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "balanced-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from murpheus import DataLoading\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "from emoji import UNICODE_EMOJI\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import emoji\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sitting-packet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:41165</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.69 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:41165' processes=4 threads=4, memory=16.69 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = DataLoading().get_twitter_data_as_bags('../../data/06/01/**/*').to_dataframe()\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the english language\n",
    "tweet_df = tweet_df[tweet_df['lang'] == 'en']\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all of the tweets that are truncated\n",
    "tweet_df['is_full_tweet'] = tweet_df.apply(lambda x: x['text'][-1] != '…', axis=1, meta=bool)\n",
    "tweet_df = tweet_df[tweet_df['is_full_tweet']]\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if there's an emoji in the text\n",
    "def is_emoji(s):\n",
    "    count = 0\n",
    "    for emoji in UNICODE_EMOJI:\n",
    "        count += s.count(emoji)\n",
    "        if count > 1:\n",
    "            return False\n",
    "    return bool(count)\n",
    "\n",
    "tweet_df = tweet_df[tweet_df['text'].apply(is_emoji, meta=bool)]\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting emoji's from the texts and how many tweets there are\n",
    "\n",
    "def extract_emojis(s):\n",
    "    return ''.join(c for c in s if c in UNICODE_EMOJI)\n",
    "\n",
    "tweet_df['emojis'] = tweet_df.apply(lambda x: extract_emojis(x['text']), axis=1, meta=str)\n",
    "tweet_df['emojis_count'] = tweet_df.apply(lambda x: len(x['emojis']), meta=int, axis=1)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing @RT from all of the tweets\n",
    "tweet_df['text_without_retweets'] = tweet_df['text'].apply(lambda x: re.sub(r'RT @(.+?):', '', x), meta=str)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only tweets with one emoji\n",
    "tweet_df = tweet_df[tweet_df['emojis_count'] == 1]\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df[['text_without_retweets', 'emojis']].to_csv('text_emoji_data/text_emoji_data-*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solid-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f2733fba34409ca02e3c2901ba6542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# process day\n",
    "# checking to see if there's an emoji in the text\n",
    "def is_emoji(s):\n",
    "    count = 0\n",
    "    for emoji in UNICODE_EMOJI:\n",
    "        count += s.count(emoji)\n",
    "        if count > 1:\n",
    "            return False\n",
    "    return bool(count)\n",
    "\n",
    "def extract_emojis(s):\n",
    "    return ''.join(c for c in s if c in UNICODE_EMOJI)\n",
    "\n",
    "for day in tqdm([1,2,4, 5, 6, 7, 8, 9, 10]):\n",
    "    day = f'0{day}' if len(str(day)) == 1 else str(day)\n",
    "    tweet_df = DataLoading().get_twitter_data_as_bags(f'../../data/06/{day}/**/*').to_dataframe()\n",
    "    # selecting only the english language\n",
    "    tweet_df = tweet_df[tweet_df['lang'] == 'en']\n",
    "    # removing all of the tweets that are truncated\n",
    "    tweet_df['is_full_tweet'] = tweet_df.apply(lambda x: x['text'][-1] != '…', axis=1, meta=bool)\n",
    "    tweet_df = tweet_df[tweet_df['is_full_tweet']]\n",
    "    tweet_df = tweet_df[tweet_df['text'].apply(is_emoji, meta=bool)]\n",
    "    tweet_df['emojis'] = tweet_df.apply(lambda x: extract_emojis(x['text']), axis=1, meta=str)\n",
    "    tweet_df['emojis_count'] = tweet_df.apply(lambda x: len(x['emojis']), meta=int, axis=1)\n",
    "    tweet_df['text_without_retweets'] = tweet_df['text'].apply(lambda x: re.sub(r'RT @(.+?):', '', x), meta=str)\n",
    "    tweet_df = tweet_df[tweet_df['emojis_count'] == 1]\n",
    "    tweet_df[['text_without_retweets', 'emojis']].to_csv(f'text_emoji_data/text_emoji_data-{day}-*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoading()\n",
    "del dl\n",
    "dl = DataLoading()\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dd.read_csv('text_emoji_data/text_emoji_data-*.csv')#[['text', 'emojis']]\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['text'] = tweet_df['text'].apply(lambda x: re.sub(r'RT @(.+?):', '', x), meta=str)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df[['text', 'emojis']].to_csv('text_emoji_data-cleaned/text_emoji_data-*.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dd.read_csv('text_emoji_data-cleaned/text_emoji_data-*.csv')#.persist()\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_counts = tweet_df.groupby('emojis').count().compute()\n",
    "emoji_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_counts = emoji_counts.sort_values('text', ascending=False).head(10)\n",
    "emoji_counts = emoji_counts.reset_index()\n",
    "emoji_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = tweet_df.loc[tweet_df.emojis.isin(emoji_counts.emojis)]\n",
    "tweet_df_training_data.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "_demojifier_regex = r':.+?:'\n",
    "_username_regex = r'@.+? '\n",
    "\n",
    "def _remove_emojis(string: str):\n",
    "    string = emoji.demojize(string)\n",
    "    return re.sub(_demojifier_regex, '', string)\n",
    "\n",
    "def filter_emoji(twitter_dataframe):\n",
    "    twitter_dataframe['text'] = twitter_dataframe['text'].apply(_remove_emojis, meta=str)\n",
    "    return twitter_dataframe\n",
    "\n",
    "def _remove_username(string: str):\n",
    "    return re.sub(_username_regex, '', string)\n",
    "\n",
    "def filter_username(twitter_dataframe):\n",
    "    twitter_dataframe['text'] = twitter_dataframe['text'].apply(_remove_username, meta=str)\n",
    "    return twitter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = filter_emoji(tweet_df_training_data)\n",
    "tweet_df_training_data = filter_username(tweet_df_training_data)\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data = tweet_df_training_data.compute()\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(tweet_df_training_data['emojis']))\n",
    "encode_key = {labels[i]:i for i in range(len(labels))}\n",
    "encode_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_training_data['encoded_emojis'] = tweet_df_training_data.apply(lambda x: encode_key[x['emojis']], axis=1)#.head()\n",
    "tweet_df_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweet_df_training_data['text'], tweet_df_training_data['encoded_emojis'])\n",
    "# y_train = tf.one_hot(y_train, depth=len(labels))\n",
    "# y_test = tf.one_hot(y_test, depth=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "# Initialize the text classifier.\n",
    "clf = ak.TextClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=5)  # It only tries 1 model as a quick demo.\n",
    "# Feed the text classifier with training data.\n",
    "clf.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the best model.\n",
    "# predicted_y = clf.predict(x_test)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
